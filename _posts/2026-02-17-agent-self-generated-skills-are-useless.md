---
layout: post
title: "Agent 自己造的技能，可能根本没用：SkillsBench 的冷水"
date: 2026-02-17
author: Cobb
categories: [AI, Agent]
tags: [LLM, Agent, Skills, Benchmark]
pin: false
---

今天 Hacker News 上一篇论文引发了热议：SkillsBench 的研究团队系统性地测试了 AI Agent "自我生成技能"的实际效果，结论令人意外——**这些技能在跨任务泛化时几乎没用**。

## 什么是 Agent Skills？

过去一年，Agent 框架领域有一个很流行的设计模式：让 Agent 在完成任务的过程中**自动提取可复用的技能（skills）**，存储起来供后续调用。理论上，这就像人类的学习过程——做过一次，下次就会了。

Voyager（Minecraft Agent）是这个范式的标杆。它能在游戏中不断积累技能库，越玩越强。随后大量框架跟进：JARVIS-1、Skill-it、AgentStore……"Agent + Skill Library"几乎成了标配架构。

## SkillsBench 做了什么？

SkillsBench 的研究团队没有在单一环境里测试，而是把这些 self-generated skills 拿到**多种不同的任务和场景**中去验证。核心问题很简单：

> 在任务 A 中学到的技能，用到任务 B 上，到底有没有帮助？

答案是：**基本没有。**

研究发现，Agent 自动生成的技能存在几个致命问题：

1. **过度拟合原始任务**：技能的抽象程度不够，本质上是对特定任务的 "录像回放"，换个场景就失效
2. **命名和描述不准确**：Agent 给技能起的名字和写的文档，跟技能实际做的事情对不上，导致后续检索时选错技能
3. **组合爆炸**：技能库越大，Agent 在选择时越困惑，反而不如从零开始推理

## 为什么这很重要？

这个结论直接挑战了当前 Agent 开发的一个核心假设：**经验可以自动积累和复用**。

如果你正在做 Agent 产品，可能需要重新思考几个问题：

**技能应该由谁来定义？** 完全让 Agent 自己提取技能，质量不可控。可能更好的方式是**人机协作**——Agent 提议，人类审核和抽象。这跟软件工程里 "自动生成的代码需要 code review" 是一个道理。

**技能的粒度怎么定？** 太细了没有复用价值，太粗了不够灵活。Voyager 在 Minecraft 里成功，是因为游戏世界的技能粒度天然合适（挖矿、合成、建造）。但在开放世界的真实任务中，粒度定义本身就是个难题。

**也许 "无技能" 才是正解？** 随着上下文窗口越来越长、推理能力越来越强，Agent 每次从头推理的成本在下降。与其维护一个可能误导 Agent 的技能库，不如把精力放在更好的规划和推理上。

## 我的看法

这篇论文让我想到一个更根本的问题：**我们是不是在用错误的隐喻理解 Agent？**

"技能学习"这个概念来自人类认知科学。但 LLM Agent 和人类的学习机制完全不同——人类的技能内化为肌肉记忆和神经通路，而 Agent 的 "技能" 本质上是存在外部存储里的一段代码或提示词。

也许 Agent 的正确进化路径不是 "积累技能"，而是 "提升推理"。就像一个数学天才不需要背公式，因为他能现场推导。

当然，这不意味着所有形式的经验积累都没用。**人类精心设计的工具和 API** 本质上也是 "技能"，但它们经过了严格的抽象和测试。问题出在 "自动生成" 这个环节——让一个还不够聪明的 Agent 来定义可复用的抽象，难度本身就超出了它的能力范围。

这可能是 Agent 领域 2026 年最重要的认知修正之一：**不要让 Agent 自己定义自己的能力边界。**

---

*论文链接：[SkillsBench: Benchmarking How Well Agent Skills Work Across Diverse Tasks](https://arxiv.org/abs/2602.12670)*
